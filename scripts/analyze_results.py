import json
import os
import glob
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# --- Configura√ß√µes Iniciais ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, '..', 'data')

PMD_REPORTS_DIR = os.path.join(DATA_DIR, 'pmd_reports', 'summaries')
CHECKSTYLE_REPORTS_DIR = os.path.join(DATA_DIR, 'checkstyle_reports', 'summaries')
LLM_RESULTS_DIR = os.path.join(DATA_DIR, 'llm_results')

OUTPUT_DIR = os.path.join(BASE_DIR, 'analysis_results')
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# Configura√ß√µes de estilo para gr√°ficos
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# --- Code Smells Comuns entre PMD e CheckStyle ---
COMMON_CODE_SMELLS = {
    "empty_catch_block",
    "unused_import",
    "cyclomatic_complexity",
    "god_class",
    "naming_conventions",
    "class_naming_conventions",
    "empty_control_statement",
    "too_many_fields"
}

# --- 1. Normaliza√ß√£o de Nomes de Code Smells ---
def normalize_smell_name(name):
    """
    Normaliza os nomes dos code smells para compara√ß√£o.
    """
    name = name.lower()
    name = name.replace('-', '_').replace(' ', '_')
    
    # Mapeamentos espec√≠ficos
    mappings = {
        "empty_catch_block": ["empty_catch_block", "emptycatchblock"],
        "cyclomatic_complexity": ["cyclomatic_complexity", "cyclomaticcomplexity"],
        "god_class": ["god_class", "godclass", "classfanoutcomplexity"],
        "class_naming_conventions": ["class_naming_conventions", "classnamingconventions", "typename"],
        "too_many_fields": ["too_many_fields", "toomanyfields", "classdataabstractioncoupling"],
        "too_many_methods": ["too_many_methods", "toomanymethods"],
        "unused_import": ["unused_import", "unnecessary_import", "unnecessaryimport", "unusedimports"],
        "empty_control_statement": ["empty_control_statement", "emptycontrolstatement", "emptystatement"],
        "naming_conventions": ["naming_conventions", "namingconventions", "typename"],
        "unused_local_variable": ["unused_local_variable", "unnecessarylocalbeforereturn"]
    }
    
    for normalized, variations in mappings.items():
        if any(var in name for var in variations):
            return normalized
    
    return name

# --- 2. Carregamento de Dados ---
def load_json_file(file_path):
    """Carrega um √∫nico arquivo JSON."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Aviso: Erro ao carregar {file_path}: {e}")
        return None

def load_tool_data(tool_summaries_path, filter_common=True):
    """
    Carrega dados de ferramentas como PMD ou CheckStyle.
    """
    data = {}
    if not os.path.isdir(tool_summaries_path):
        print(f"Aviso: Diret√≥rio n√£o encontrado {tool_summaries_path}")
        return data

    for file_path in glob.glob(os.path.join(tool_summaries_path, '*.json')):
        content = load_json_file(file_path)
        if content and 'repository' in content:
            repo_name = content['repository']
            normalized_smells = {}
            
            for k, v in content.get('code_smells', {}).items():
                normalized_name = normalize_smell_name(k)
                if normalized_name and (not filter_common or normalized_name in COMMON_CODE_SMELLS):
                    normalized_smells[normalized_name] = normalized_smells.get(normalized_name, 0) + v
            
            data[repo_name] = {
                "code_smells": normalized_smells,
                "total_smells": sum(normalized_smells.values())
            }
    return data

def load_llm_data_for_prompt(llm_base_path, prompt_type, filter_common=True):
    """
    Carrega dados da LLM para um tipo de prompt espec√≠fico.
    """
    data = {}
    if not os.path.isdir(llm_base_path):
        print(f"Aviso: Diret√≥rio base da LLM n√£o encontrado {llm_base_path}")
        return data

    for repo_folder_name in os.listdir(llm_base_path):
        repo_folder_path = os.path.join(llm_base_path, repo_folder_name)
        if os.path.isdir(repo_folder_path):
            repo_name = repo_folder_name
            file_path = os.path.join(repo_folder_path, f"{prompt_type}.json")
            content = load_json_file(file_path)
            
            if content:
                if 'repository' not in content:
                    content['repository'] = repo_name

                normalized_smells = {}
                for k, v in content.get('code_smells', {}).items():
                    normalized_name = normalize_smell_name(k)
                    if normalized_name and (not filter_common or normalized_name in COMMON_CODE_SMELLS):
                        normalized_smells[normalized_name] = normalized_smells.get(normalized_name, 0) + v
                
                data[repo_name] = {
                    "code_smells": normalized_smells,
                    "total_smells": sum(normalized_smells.values())
                }
    return data

# --- 3. C√°lculo de M√©tricas ---
def get_all_repositories(datasets):
    """Retorna um conjunto de todos os nomes de reposit√≥rios presentes nos datasets."""
    all_repos = set()
    for data in datasets:
        all_repos.update(data.keys())
    return sorted(list(all_repos))

def calculate_total_smells_per_tool(data_dict, tool_name, all_repositories):
    """Calcula o n√∫mero total de smells para uma ferramenta/abordagem."""
    total = 0
    for repo in all_repositories:
        total += data_dict.get(repo, {}).get('total_smells', 0)
    return {tool_name: total}

def calculate_average_difference(data1, data2, name1, name2, all_repositories):
    """Calcula a diferen√ßa m√©dia de detec√ß√£o por reposit√≥rio."""
    differences = []
    for repo in all_repositories:
        smells1 = data1.get(repo, {}).get('total_smells', 0)
        smells2 = data2.get(repo, {}).get('total_smells', 0)
        differences.append(smells1 - smells2)
    
    return np.mean(differences) if differences else 0

def calculate_corpus_metrics(llm_data, tool_data, all_repositories):
    """
    Calcula Similaridade e Diverg√™ncia usando a f√≥rmula de Jaccard.
    """
    corpus_llm_smells = defaultdict(int)
    corpus_tool_smells = defaultdict(int)

    for repo in all_repositories:
        repo_llm_data = llm_data.get(repo, {"code_smells": {}})
        repo_tool_data = tool_data.get(repo, {"code_smells": {}})

        for smell, count in repo_llm_data["code_smells"].items():
            corpus_llm_smells[smell] += count
        for smell, count in repo_tool_data["code_smells"].items():
            corpus_tool_smells[smell] += count

    # Interse√ß√£o e Uni√£o
    intersection_sum = 0
    all_smell_types = set(corpus_llm_smells.keys()) | set(corpus_tool_smells.keys())
    
    for s_type in all_smell_types:
        llm_count = corpus_llm_smells.get(s_type, 0)
        tool_count = corpus_tool_smells.get(s_type, 0)
        intersection_sum += min(llm_count, tool_count)
    
    # Uni√£o
    union_sum = sum(corpus_llm_smells.values()) + sum(corpus_tool_smells.values()) - intersection_sum
    
    if union_sum == 0:
        similarity_rate = 0.0
        divergence_rate = 0.0
    else:
        similarity_rate = (intersection_sum / union_sum) * 100
        
        # Diverg√™ncia: LLM - Ferramenta
        llm_minus_tool = sum(corpus_llm_smells.values()) - intersection_sum
        divergence_rate = (llm_minus_tool / union_sum) * 100
        
    return similarity_rate, divergence_rate

def prepare_detailed_comparison_data(llm_data, tool_data, all_repositories):
    """Prepara dados detalhados para visualiza√ß√µes avan√ßadas."""
    comparison_data = []
    
    for repo in all_repositories:
        llm_smells = llm_data.get(repo, {"code_smells": {}})["code_smells"]
        tool_smells = tool_data.get(repo, {"code_smells": {}})["code_smells"]
        
        all_smells_in_repo = set(llm_smells.keys()) | set(tool_smells.keys())
        
        for smell in all_smells_in_repo:
            comparison_data.append({
                'repository': repo,
                'code_smell': smell,
                'llm_count': llm_smells.get(smell, 0),
                'tool_count': tool_smells.get(smell, 0)
            })
    
    return pd.DataFrame(comparison_data)

# --- 4. Fun√ß√µes de Plotagem Aprimoradas ---
def plot_enhanced_bar_chart(data_dict, title, xlabel, ylabel, filename):
    """Gr√°fico de barras aprimorado com gradientes."""
    fig, ax = plt.subplots(figsize=(12, 8))
    
    names = list(data_dict.keys())
    values = list(data_dict.values())
    
    # Cores com gradiente
    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(names)))
    
    bars = ax.bar(names, values, color=colors, edgecolor='black', linewidth=1.5)
    
    # Adicionar valores nas barras
    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,
                f'{int(val)}', ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    ax.set_xlabel(xlabel, fontsize=14)
    ax.set_ylabel(ylabel, fontsize=14)
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3)
    
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close()

def plot_scatter_comparison(df, llm_name, tool_name, filename):
    """Cria scatter plot melhorado para compara√ß√£o entre LLM e ferramenta."""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # Preparar dados - duas agrega√ß√µes diferentes
    # 1. Por code smell (soma total)
    smell_summary = df.groupby('code_smell').agg({
        'llm_count': 'sum',
        'tool_count': 'sum'
    }).reset_index()
    
    # 2. Por reposit√≥rio (soma total)
    repo_summary = df.groupby('repository').agg({
        'llm_count': 'sum',
        'tool_count': 'sum'
    }).reset_index()
    
    # --- Subplot 1: Por Code Smell ---
    # Cores baseadas na diferen√ßa percentual
    smell_summary['diff_percent'] = ((smell_summary['llm_count'] - smell_summary['tool_count']) / 
                                     (smell_summary['tool_count'] + 1)) * 100
    
    # Tamanho dos pontos baseado no total de detec√ß√µes
    smell_summary['total'] = smell_summary['llm_count'] + smell_summary['tool_count']
    sizes = 100 + (smell_summary['total'] / smell_summary['total'].max()) * 400
    
    scatter1 = ax1.scatter(smell_summary['tool_count'], 
                          smell_summary['llm_count'],
                          s=sizes, 
                          c=smell_summary['diff_percent'],
                          cmap='RdYlBu', 
                          alpha=0.7,
                          edgecolors='black', 
                          linewidth=1.5)
    
    # Linha de refer√™ncia (y=x)
    max_val1 = max(smell_summary['tool_count'].max(), smell_summary['llm_count'].max()) * 1.1
    ax1.plot([0, max_val1], [0, max_val1], 'k--', alpha=0.5, linewidth=2, label='Linha de igualdade')
    
    # Adicionar anota√ß√µes para pontos significativos
    for idx, row in smell_summary.iterrows():
        # Anotar apenas pontos com diferen√ßa significativa ou total alto
        if abs(row['diff_percent']) > 50 or row['total'] > smell_summary['total'].median():
            ax1.annotate(row['code_smell'].replace('_', ' ').title(), 
                        (row['tool_count'], row['llm_count']),
                        xytext=(10, 10), 
                        textcoords='offset points',
                        fontsize=10, 
                        alpha=0.9,
                        bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.7),
                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0.3', alpha=0.5))
    
    # Configura√ß√µes do subplot 1
    ax1.set_xlabel(f'{tool_name} - Total de Detec√ß√µes', fontsize=14, fontweight='bold')
    ax1.set_ylabel(f'{llm_name} - Total de Detec√ß√µes', fontsize=14, fontweight='bold')
    ax1.set_title(f'Compara√ß√£o por Tipo de Code Smell', fontsize=16, fontweight='bold')
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.set_axisbelow(True)
    
    # Adicionar zonas de interpreta√ß√£o
    ax1.fill_between([0, max_val1], [0, 0], [0, max_val1], 
                     where=[True, True], alpha=0.1, color='red', 
                     label=f'{tool_name} detecta mais')
    ax1.fill_between([0, max_val1], [0, max_val1], [max_val1, max_val1], 
                     where=[True, True], alpha=0.1, color='blue', 
                     label=f'{llm_name} detecta mais')
    
    # Colorbar para o subplot 1
    cbar1 = plt.colorbar(scatter1, ax=ax1)
    cbar1.set_label('Diferen√ßa % (LLM - Ferramenta)', fontsize=12)
    
    ax1.legend(loc='upper left', fontsize=11)
    
    # --- Subplot 2: Por Reposit√≥rio ---
    # Calcular m√©tricas para colora√ß√£o
    repo_summary['diff_percent'] = ((repo_summary['llm_count'] - repo_summary['tool_count']) / 
                                    (repo_summary['tool_count'] + 1)) * 100
    
    scatter2 = ax2.scatter(repo_summary['tool_count'], 
                          repo_summary['llm_count'],
                          s=150, 
                          c=repo_summary['diff_percent'],
                          cmap='RdYlBu', 
                          alpha=0.7,
                          edgecolors='black', 
                          linewidth=1.5,
                          marker='D')  # Diamante para diferenciar
    
    # Linha de refer√™ncia
    max_val2 = max(repo_summary['tool_count'].max(), repo_summary['llm_count'].max()) * 1.1
    ax2.plot([0, max_val2], [0, max_val2], 'k--', alpha=0.5, linewidth=2)
    
    # Adicionar estat√≠sticas no gr√°fico
    correlation = repo_summary[['tool_count', 'llm_count']].corr().iloc[0, 1]
    textstr = f'Correla√ß√£o: {correlation:.3f}\n'
    textstr += f'Reposit√≥rios: {len(repo_summary)}\n'
    textstr += f'{llm_name} > {tool_name}: {(repo_summary["llm_count"] > repo_summary["tool_count"]).sum()}\n'
    textstr += f'{tool_name} > {llm_name}: {(repo_summary["tool_count"] > repo_summary["llm_count"]).sum()}'
    
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    ax2.text(0.05, 0.95, textstr, transform=ax2.transAxes, fontsize=11,
            verticalalignment='top', bbox=props)
    
    # Configura√ß√µes do subplot 2
    ax2.set_xlabel(f'{tool_name} - Total de Detec√ß√µes', fontsize=14, fontweight='bold')
    ax2.set_ylabel(f'{llm_name} - Total de Detec√ß√µes', fontsize=14, fontweight='bold')
    ax2.set_title(f'Compara√ß√£o por Reposit√≥rio', fontsize=16, fontweight='bold')
    ax2.grid(True, alpha=0.3, linestyle='--')
    ax2.set_axisbelow(True)
    
    # Colorbar para o subplot 2
    cbar2 = plt.colorbar(scatter2, ax=ax2)
    cbar2.set_label('Diferen√ßa % (LLM - Ferramenta)', fontsize=12)
    
    # T√≠tulo geral
    fig.suptitle(f'An√°lise Comparativa: {llm_name} vs {tool_name}', 
                 fontsize=18, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close()
    
    # --- Gr√°fico adicional: Violin Plot ---
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Preparar dados para violin plot
    violin_data = []
    for _, row in df.iterrows():
        if row['llm_count'] > 0:
            violin_data.extend([llm_name] * int(row['llm_count']))
        if row['tool_count'] > 0:
            violin_data.extend([tool_name] * int(row['tool_count']))
    
    # Criar DataFrame para violin plot
    if violin_data:  # Apenas se houver dados
        violin_df = pd.DataFrame({'Tool': violin_data})
        violin_df['Count'] = 1
        
        # Agregar por reposit√≥rio e ferramenta
        plot_data = []
        for repo in df['repository'].unique():
            repo_data = df[df['repository'] == repo]
            plot_data.append({
                'Tool': llm_name,
                'Count': repo_data['llm_count'].sum(),
                'Repository': repo
            })
            plot_data.append({
                'Tool': tool_name,
                'Count': repo_data['tool_count'].sum(),
                'Repository': repo
            })
        
        plot_df = pd.DataFrame(plot_data)
        
        # Criar violin plot
        sns.violinplot(data=plot_df, x='Tool', y='Count', ax=ax, inner='box', palette='Set2')
        
        # Adicionar pontos individuais
        sns.stripplot(data=plot_df, x='Tool', y='Count', ax=ax, 
                     size=4, color='black', alpha=0.3)
        
        ax.set_title(f'Distribui√ß√£o de Detec√ß√µes por Reposit√≥rio\n{llm_name} vs {tool_name}', 
                    fontsize=16, fontweight='bold')
        ax.set_ylabel('Total de Code Smells por Reposit√≥rio', fontsize=14)
        ax.set_xlabel('Ferramenta', fontsize=14)
        ax.grid(True, alpha=0.3, axis='y')
        
        # Adicionar m√©dias
        means = plot_df.groupby('Tool')['Count'].mean()
        for i, (tool, mean) in enumerate(means.items()):
            ax.hlines(mean, i-0.4, i+0.4, colors='red', linestyles='dashed', linewidth=2)
            ax.text(i, mean + plot_df['Count'].max()*0.02, f'M√©dia: {mean:.1f}', 
                   ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_DIR, filename.replace('.png', '_violin.png')), 
                   dpi=300, bbox_inches='tight')
        plt.close()

def plot_heatmap_comparison(llm_data, tool_data, all_repositories, llm_name, tool_name, filename):
    """Cria heatmap para compara√ß√£o entre reposit√≥rios e code smells."""
    # Preparar matriz de dados
    all_smells = set()
    for repo in all_repositories:
        all_smells.update(llm_data.get(repo, {"code_smells": {}})["code_smells"].keys())
        all_smells.update(tool_data.get(repo, {"code_smells": {}})["code_smells"].keys())
    
    all_smells = sorted(list(all_smells))
    
    # Criar matriz de diferen√ßa
    diff_matrix = np.zeros((len(all_repositories), len(all_smells)))
    
    for i, repo in enumerate(all_repositories):
        for j, smell in enumerate(all_smells):
            llm_count = llm_data.get(repo, {"code_smells": {}})["code_smells"].get(smell, 0)
            tool_count = tool_data.get(repo, {"code_smells": {}})["code_smells"].get(smell, 0)
            diff_matrix[i, j] = llm_count - tool_count
    
    # Criar heatmap
    fig, ax = plt.subplots(figsize=(14, 10))
    
    # Criar m√°scaras para valores zero
    mask = diff_matrix == 0
    
    sns.heatmap(diff_matrix, 
                xticklabels=all_smells,
                yticklabels=all_repositories,
                cmap='RdBu_r',
                center=0,
                annot=True,
                fmt='.0f',
                mask=mask,
                cbar_kws={'label': f'Diferen√ßa ({llm_name} - {tool_name})'},
                ax=ax)
    
    ax.set_title(f'Heatmap de Diferen√ßas: {llm_name} - {tool_name}', fontsize=16, fontweight='bold', pad=20)
    ax.set_xlabel('Code Smells', fontsize=14)
    ax.set_ylabel('Reposit√≥rios', fontsize=14)
    
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close()

def plot_grouped_bar_enhanced(data_dict, title, filename):
    """Gr√°fico de barras agrupadas aprimorado."""
    df = pd.DataFrame(data_dict)
    
    fig, ax = plt.subplots(figsize=(14, 8))
    
    x = np.arange(len(df.columns))
    width = 0.35
    
    # Cores distintas para cada m√©trica
    colors = ['#3498db', '#e74c3c']
    
    for i, (metric, row) in enumerate(df.iterrows()):
        offset = width * (i - len(df) / 2 + 0.5)
        bars = ax.bar(x + offset, row, width, label=metric, color=colors[i], alpha=0.8, edgecolor='black')
        
        # Adicionar valores nas barras
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{height:.1f}%', ha='center', va='bottom', fontsize=10)
    
    ax.set_xlabel('Compara√ß√µes', fontsize=14)
    ax.set_ylabel('Taxa (%)', fontsize=14)
    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)
    ax.set_xticks(x)
    ax.set_xticklabels(df.columns, rotation=45, ha='right')
    ax.legend(fontsize=12)
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close()

def create_summary_report(results_dict, filename):
    """Cria um relat√≥rio resumido em formato de tabela."""
    fig, ax = plt.subplots(figsize=(16, 10))
    ax.axis('tight')
    ax.axis('off')
    
    # Preparar dados para tabela
    table_data = []
    headers = ['Quest√£o', 'M√©trica', 'Valor', 'Interpreta√ß√£o']
    
    for question, metrics in results_dict.items():
        for metric_name, value in metrics.items():
            interpretation = ""
            if "similaridade" in metric_name.lower():
                interpretation = "Alta" if value > 70 else "M√©dia" if value > 40 else "Baixa"
            elif "diverg√™ncia" in metric_name.lower():
                interpretation = "Alta" if value > 30 else "M√©dia" if value > 15 else "Baixa"
            elif "diferen√ßa" in metric_name.lower():
                interpretation = "LLM detecta mais" if value > 0 else "Ferramenta detecta mais"
            
            table_data.append([question, metric_name, f"{value:.2f}", interpretation])
    
    # Criar tabela
    table = ax.table(cellText=table_data,
                     colLabels=headers,
                     cellLoc='center',
                     loc='center',
                     colWidths=[0.15, 0.45, 0.15, 0.25])
    
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1.2, 1.5)
    
    # Estilizar cabe√ßalho
    for i in range(len(headers)):
        table[(0, i)].set_facecolor('#3498db')
        table[(0, i)].set_text_props(weight='bold', color='white')
    
    # Estilizar linhas alternadas
    for i in range(1, len(table_data) + 1):
        for j in range(len(headers)):
            if i % 2 == 0:
                table[(i, j)].set_facecolor('#ecf0f1')
    
    ax.set_title('Relat√≥rio Resumido - An√°lise de Code Smells', fontsize=18, fontweight='bold', pad=20)
    
    plt.savefig(os.path.join(OUTPUT_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close()

# --- 5. L√≥gica Principal do Script ---
def main():
    print("=" * 80)
    print("AN√ÅLISE APRIMORADA DE CODE SMELLS - LLM vs FERRAMENTAS")
    print("=" * 80)
    print()
    
    # Op√ß√£o para filtrar apenas code smells comuns
    filter_common = True
    print(f"Filtro de code smells comuns: {'ATIVADO' if filter_common else 'DESATIVADO'}")
    print(f"Code smells considerados: {', '.join(sorted(COMMON_CODE_SMELLS))}")
    print()
    
    # Carregar dados
    print("üìä Carregando dados...")
    pmd_data = load_tool_data(PMD_REPORTS_DIR, filter_common)
    print(f"‚úì PMD: {len(pmd_data)} reposit√≥rios carregados")
    
    checkstyle_data = load_tool_data(CHECKSTYLE_REPORTS_DIR, filter_common)
    print(f"‚úì CheckStyle: {len(checkstyle_data)} reposit√≥rios carregados")
    
    llm_zeroshot_data = load_llm_data_for_prompt(LLM_RESULTS_DIR, "zero_shot", filter_common)
    print(f"‚úì LLM Zero-Shot: {len(llm_zeroshot_data)} reposit√≥rios carregados")
    
    llm_oneshot_data = load_llm_data_for_prompt(LLM_RESULTS_DIR, "one_shot", filter_common)
    print(f"‚úì LLM One-Shot: {len(llm_oneshot_data)} reposit√≥rios carregados")
    
    llm_calibrated_data = load_llm_data_for_prompt(LLM_RESULTS_DIR, "prompt_calibrado", filter_common)
    print(f"‚úì LLM Calibrado: {len(llm_calibrated_data)} reposit√≥rios carregados")
    print()
    
    all_repos = get_all_repositories([pmd_data, checkstyle_data, llm_zeroshot_data, llm_oneshot_data, llm_calibrated_data])
    
    if not all_repos:
        print("‚ùå Nenhum dado de reposit√≥rio encontrado. Verifique os caminhos e os arquivos.")
        return
    
    print(f"üìÅ Total de reposit√≥rios √∫nicos: {len(all_repos)}")
    print("-" * 80)
    
    # Dicion√°rio para armazenar todos os resultados
    all_results = {}
    
    # --- Question 1: LLM zero-shot vs PMD vs CheckStyle ---
    print("\nüîç QUEST√ÉO 1: LLM (Zero-Shot) vs PMD vs CheckStyle")
    print("-" * 80)
    
    q1_results = {}
    
    # M√©trica 1.1
    q1_totals = {}
    q1_totals.update(calculate_total_smells_per_tool(llm_zeroshot_data, "LLM Zero-Shot", all_repos))
    q1_totals.update(calculate_total_smells_per_tool(pmd_data, "PMD", all_repos))
    q1_totals.update(calculate_total_smells_per_tool(checkstyle_data, "CheckStyle", all_repos))
    
    print("üìà M√©trica 1.1 - Total de code smells detectados:")
    for tool, total in q1_totals.items():
        print(f"   ‚Ä¢ {tool}: {total}")
        q1_results[f"1.1 - Total {tool}"] = total
    
    plot_enhanced_bar_chart(q1_totals, "Q1: Total de Code Smells Detectados", 
                           "Abordagem", "Total de Smells", "q1_metric1_1_total_smells.png")
    
    # M√©trica 1.2
    q1_avg_diff_llm_pmd = calculate_average_difference(llm_zeroshot_data, pmd_data, "LLM_Zero_Shot", "PMD", all_repos)
    q1_avg_diff_llm_cs = calculate_average_difference(llm_zeroshot_data, checkstyle_data, "LLM_Zero_Shot", "CheckStyle", all_repos)
    
    print(f"\nüìä M√©trica 1.2 - Diferen√ßa m√©dia por reposit√≥rio:")
    print(f"   ‚Ä¢ LLM Zero-Shot - PMD: {q1_avg_diff_llm_pmd:.2f}")
    print(f"   ‚Ä¢ LLM Zero-Shot - CheckStyle: {q1_avg_diff_llm_cs:.2f}")
    
    q1_results["1.2 - Dif. M√©dia LLM_ZS-PMD"] = q1_avg_diff_llm_pmd
    q1_results["1.2 - Dif. M√©dia LLM_ZS-CS"] = q1_avg_diff_llm_cs
    
    plot_enhanced_bar_chart({"LLM ZS - PMD": q1_avg_diff_llm_pmd, "LLM ZS - CheckStyle": q1_avg_diff_llm_cs},
                           "Q1: Diferen√ßa M√©dia de Detec√ß√£o por Reposit√≥rio", 
                           "Compara√ß√£o", "Diferen√ßa M√©dia", "q1_metric1_2_avg_diff.png")
    
    # M√©tricas 1.3-1.6
    sim_llm_zs_pmd, div_llm_zs_pmd = calculate_corpus_metrics(llm_zeroshot_data, pmd_data, all_repos)
    sim_llm_zs_cs, div_llm_zs_cs = calculate_corpus_metrics(llm_zeroshot_data, checkstyle_data, all_repos)
    
    print(f"\nüîÑ M√©tricas 1.3-1.6 - Similaridade e Diverg√™ncia:")
    print(f"   ‚Ä¢ LLM ZS vs PMD:")
    print(f"     - Similaridade: {sim_llm_zs_pmd:.2f}%")
    print(f"     - Diverg√™ncia: {div_llm_zs_pmd:.2f}%")
    print(f"   ‚Ä¢ LLM ZS vs CheckStyle:")
    print(f"     - Similaridade: {sim_llm_zs_cs:.2f}%")
    print(f"     - Diverg√™ncia: {div_llm_zs_cs:.2f}%")
    
    q1_results["1.3 - Similaridade LLM_ZS vs PMD"] = sim_llm_zs_pmd
    q1_results["1.4 - Diverg√™ncia LLM_ZS vs PMD"] = div_llm_zs_pmd
    q1_results["1.5 - Similaridade LLM_ZS vs CS"] = sim_llm_zs_cs
    q1_results["1.6 - Diverg√™ncia LLM_ZS vs CS"] = div_llm_zs_cs
    
    all_results["Quest√£o 1"] = q1_results
    
    q1_sim_div_data = {
        'LLM ZS vs PMD': {"Similaridade (%)": sim_llm_zs_pmd, "Diverg√™ncia (%)": div_llm_zs_pmd},
        'LLM ZS vs CheckStyle': {"Similaridade (%)": sim_llm_zs_cs, "Diverg√™ncia (%)": div_llm_zs_cs}
    }
    plot_grouped_bar_enhanced(q1_sim_div_data, "Q1: Similaridade e Diverg√™ncia - LLM Zero-Shot", 
                             "q1_metrics_1_3_to_1_6_sim_div.png")
    
    # Visualiza√ß√µes adicionais Q1
    df_comparison_zs_pmd = prepare_detailed_comparison_data(llm_zeroshot_data, pmd_data, all_repos)
    plot_scatter_comparison(df_comparison_zs_pmd, "LLM Zero-Shot", "PMD", "q1_scatter_llm_zs_vs_pmd.png")
    
    df_comparison_zs_cs = prepare_detailed_comparison_data(llm_zeroshot_data, checkstyle_data, all_repos)
    plot_scatter_comparison(df_comparison_zs_cs, "LLM Zero-Shot", "CheckStyle", "q1_scatter_llm_zs_vs_checkstyle.png")
    
    plot_heatmap_comparison(llm_zeroshot_data, pmd_data, all_repos[:10], "LLM Zero-Shot", "PMD", "q1_heatmap_llm_zs_vs_pmd.png")
    
    # --- Question 2: LLM one-shot vs PMD vs CheckStyle ---
    print("\n" + "=" * 80)
    print("üîç QUEST√ÉO 2: LLM (One-Shot) vs PMD vs CheckStyle")
    print("-" * 80)
    
    q2_results = {}
    
    # M√©trica 2.1
    q2_totals = {}
    q2_totals.update(calculate_total_smells_per_tool(llm_oneshot_data, "LLM One-Shot", all_repos))
    q2_totals.update(calculate_total_smells_per_tool(pmd_data, "PMD", all_repos))
    q2_totals.update(calculate_total_smells_per_tool(checkstyle_data, "CheckStyle", all_repos))
    
    print("üìà M√©trica 2.1 - Total de code smells detectados:")
    for tool, total in q2_totals.items():
        print(f"   ‚Ä¢ {tool}: {total}")
        q2_results[f"2.1 - Total {tool}"] = total
    
    plot_enhanced_bar_chart(q2_totals, "Q2: Total de Code Smells Detectados", 
                           "Abordagem", "Total de Smells", "q2_metric2_1_total_smells.png")
    
    # M√©trica 2.2
    q2_avg_diff_llm_pmd = calculate_average_difference(llm_oneshot_data, pmd_data, "LLM_One_Shot", "PMD", all_repos)
    q2_avg_diff_llm_cs = calculate_average_difference(llm_oneshot_data, checkstyle_data, "LLM_One_Shot", "CheckStyle", all_repos)
    
    print(f"\nüìä M√©trica 2.2 - Diferen√ßa m√©dia por reposit√≥rio:")
    print(f"   ‚Ä¢ LLM One-Shot - PMD: {q2_avg_diff_llm_pmd:.2f}")
    print(f"   ‚Ä¢ LLM One-Shot - CheckStyle: {q2_avg_diff_llm_cs:.2f}")
    
    q2_results["2.2 - Dif. M√©dia LLM_OS-PMD"] = q2_avg_diff_llm_pmd
    q2_results["2.2 - Dif. M√©dia LLM_OS-CS"] = q2_avg_diff_llm_cs
    
    plot_enhanced_bar_chart({"LLM OS - PMD": q2_avg_diff_llm_pmd, "LLM OS - CheckStyle": q2_avg_diff_llm_cs},
                           "Q2: Diferen√ßa M√©dia de Detec√ß√£o por Reposit√≥rio", 
                           "Compara√ß√£o", "Diferen√ßa M√©dia", "q2_metric2_2_avg_diff.png")
    
    # M√©tricas 2.3-2.6
    sim_llm_os_pmd, div_llm_os_pmd = calculate_corpus_metrics(llm_oneshot_data, pmd_data, all_repos)
    sim_llm_os_cs, div_llm_os_cs = calculate_corpus_metrics(llm_oneshot_data, checkstyle_data, all_repos)
    
    print(f"\nüîÑ M√©tricas 2.3-2.6 - Similaridade e Diverg√™ncia:")
    print(f"   ‚Ä¢ LLM OS vs PMD:")
    print(f"     - Similaridade: {sim_llm_os_pmd:.2f}%")
    print(f"     - Diverg√™ncia: {div_llm_os_pmd:.2f}%")
    print(f"   ‚Ä¢ LLM OS vs CheckStyle:")
    print(f"     - Similaridade: {sim_llm_os_cs:.2f}%")
    print(f"     - Diverg√™ncia: {div_llm_os_cs:.2f}%")
    
    q2_results["2.3 - Similaridade LLM_OS vs PMD"] = sim_llm_os_pmd
    q2_results["2.4 - Diverg√™ncia LLM_OS vs PMD"] = div_llm_os_pmd
    q2_results["2.5 - Similaridade LLM_OS vs CS"] = sim_llm_os_cs
    q2_results["2.6 - Diverg√™ncia LLM_OS vs CS"] = div_llm_os_cs
    
    all_results["Quest√£o 2"] = q2_results
    
    q2_sim_div_data = {
        'LLM OS vs PMD': {"Similaridade (%)": sim_llm_os_pmd, "Diverg√™ncia (%)": div_llm_os_pmd},
        'LLM OS vs CheckStyle': {"Similaridade (%)": sim_llm_os_cs, "Diverg√™ncia (%)": div_llm_os_cs}
    }
    plot_grouped_bar_enhanced(q2_sim_div_data, "Q2: Similaridade e Diverg√™ncia - LLM One-Shot", 
                             "q2_metrics_2_3_to_2_6_sim_div.png")
    
    # Visualiza√ß√µes adicionais Q2
    df_comparison_os_pmd = prepare_detailed_comparison_data(llm_oneshot_data, pmd_data, all_repos)
    plot_scatter_comparison(df_comparison_os_pmd, "LLM One-Shot", "PMD", "q2_scatter_llm_os_vs_pmd.png")
    
    df_comparison_os_cs = prepare_detailed_comparison_data(llm_oneshot_data, checkstyle_data, all_repos)
    plot_scatter_comparison(df_comparison_os_cs, "LLM One-Shot", "CheckStyle", "q2_scatter_llm_os_vs_checkstyle.png")
    
    plot_heatmap_comparison(llm_oneshot_data, pmd_data, all_repos[:10], "LLM One-Shot", "PMD", "q2_heatmap_llm_os_vs_pmd.png")
    
    # --- Question 3: LLM calibrado vs PMD ---
    print("\n" + "=" * 80)
    print("üîç QUEST√ÉO 3: LLM (Prompt Calibrado) vs PMD")
    print("-" * 80)
    
    q3_results = {}
    
    # M√©trica 3.1
    q3_totals = {}
    q3_totals.update(calculate_total_smells_per_tool(llm_calibrated_data, "LLM Calibrado", all_repos))
    q3_totals.update(calculate_total_smells_per_tool(pmd_data, "PMD", all_repos))
    
    print("üìà M√©trica 3.1 - Total de code smells detectados:")
    for tool, total in q3_totals.items():
        print(f"   ‚Ä¢ {tool}: {total}")
        q3_results[f"3.1 - Total {tool}"] = total
    
    plot_enhanced_bar_chart(q3_totals, "Q3: Total de Code Smells Detectados", 
                           "Abordagem", "Total de Smells", "q3_metric3_1_total_smells.png")
    
    # M√©trica 3.2
    q3_avg_diff_llm_pmd = calculate_average_difference(llm_calibrated_data, pmd_data, "LLM_Calibrado", "PMD", all_repos)
    
    print(f"\nüìä M√©trica 3.2 - Diferen√ßa m√©dia por reposit√≥rio:")
    print(f"   ‚Ä¢ LLM Calibrado - PMD: {q3_avg_diff_llm_pmd:.2f}")
    
    q3_results["3.2 - Dif. M√©dia LLM_Cal-PMD"] = q3_avg_diff_llm_pmd
    
    plot_enhanced_bar_chart({"LLM Calibrado - PMD": q3_avg_diff_llm_pmd},
                           "Q3: Diferen√ßa M√©dia de Detec√ß√£o por Reposit√≥rio", 
                           "Compara√ß√£o", "Diferen√ßa M√©dia", "q3_metric3_2_avg_diff.png")
    
    # M√©tricas 3.3-3.4
    sim_llm_cal_pmd, div_llm_cal_pmd = calculate_corpus_metrics(llm_calibrated_data, pmd_data, all_repos)
    
    print(f"\nüîÑ M√©tricas 3.3-3.4 - Similaridade e Diverg√™ncia:")
    print(f"   ‚Ä¢ LLM Calibrado vs PMD:")
    print(f"     - Similaridade: {sim_llm_cal_pmd:.2f}%")
    print(f"     - Diverg√™ncia: {div_llm_cal_pmd:.2f}%")
    
    q3_results["3.3 - Similaridade LLM_Cal vs PMD"] = sim_llm_cal_pmd
    q3_results["3.4 - Diverg√™ncia LLM_Cal vs PMD"] = div_llm_cal_pmd
    
    all_results["Quest√£o 3"] = q3_results
    
    q3_sim_div_data = {
        'LLM Calibrado vs PMD': {"Similaridade (%)": sim_llm_cal_pmd, "Diverg√™ncia (%)": div_llm_cal_pmd}
    }
    plot_grouped_bar_enhanced(q3_sim_div_data, "Q3: Similaridade e Diverg√™ncia - LLM Calibrado vs PMD", 
                             "q3_metrics_3_3_to_3_4_sim_div.png")
    
    # Visualiza√ß√µes adicionais Q3
    df_comparison_cal_pmd = prepare_detailed_comparison_data(llm_calibrated_data, pmd_data, all_repos)
    plot_scatter_comparison(df_comparison_cal_pmd, "LLM Calibrado", "PMD", "q3_scatter_llm_cal_vs_pmd.png")
    
    plot_heatmap_comparison(llm_calibrated_data, pmd_data, all_repos[:10], "LLM Calibrado", "PMD", "q3_heatmap_llm_cal_vs_pmd.png")
    
    # --- An√°lises Adicionais ---
    print("\n" + "=" * 80)
    print("üìä AN√ÅLISES ADICIONAIS")
    print("-" * 80)
    
    # Compara√ß√£o entre todos os prompts LLM
    llm_comparison = {
        "LLM Zero-Shot": calculate_total_smells_per_tool(llm_zeroshot_data, "LLM Zero-Shot", all_repos)["LLM Zero-Shot"],
        "LLM One-Shot": calculate_total_smells_per_tool(llm_oneshot_data, "LLM One-Shot", all_repos)["LLM One-Shot"],
        "LLM Calibrado": calculate_total_smells_per_tool(llm_calibrated_data, "LLM Calibrado", all_repos)["LLM Calibrado"]
    }
    
    print("\nüìà Compara√ß√£o entre prompts LLM:")
    for prompt, total in llm_comparison.items():
        print(f"   ‚Ä¢ {prompt}: {total}")
    
    plot_enhanced_bar_chart(llm_comparison, "Compara√ß√£o entre Prompts LLM", 
                           "Tipo de Prompt", "Total de Smells", "comparison_llm_prompts.png")
    
    # An√°lise por tipo de code smell
    print("\nüîç An√°lise por tipo de code smell (top 5 mais detectados):")
    
    all_smell_counts = defaultdict(int)
    for data_source in [pmd_data, checkstyle_data, llm_zeroshot_data, llm_oneshot_data, llm_calibrated_data]:
        for repo_data in data_source.values():
            for smell, count in repo_data["code_smells"].items():
                all_smell_counts[smell] += count
    
    top_smells = sorted(all_smell_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    print("   Top 5 code smells mais detectados:")
    for smell, count in top_smells:
        print(f"   ‚Ä¢ {smell}: {count}")
    
    # Criar gr√°fico de distribui√ß√£o por tipo de smell
    smell_distribution = {}
    tools = [
        ("LLM Zero-Shot", llm_zeroshot_data),
        ("LLM One-Shot", llm_oneshot_data),
        ("LLM Calibrado", llm_calibrated_data),
        ("PMD", pmd_data),
        ("CheckStyle", checkstyle_data)
    ]
    
    for smell, _ in top_smells:
        smell_distribution[smell] = {}
        for tool_name, tool_data in tools:
            total = sum(repo_data["code_smells"].get(smell, 0) for repo_data in tool_data.values())
            smell_distribution[smell][tool_name] = total
    
    # Criar DataFrame para visualiza√ß√£o
    smell_df = pd.DataFrame(smell_distribution).T
    
    # Gr√°fico de barras empilhadas
    fig, ax = plt.subplots(figsize=(14, 8))
    smell_df.plot(kind='bar', ax=ax, width=0.8)
    ax.set_title("Distribui√ß√£o dos Top 5 Code Smells por Ferramenta", fontsize=16, fontweight='bold')
    ax.set_xlabel("Tipo de Code Smell", fontsize=14)
    ax.set_ylabel("Total de Detec√ß√µes", fontsize=14)
    ax.legend(title="Ferramenta", bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, "distribution_top_smells_by_tool.png"), dpi=300, bbox_inches='tight')
    plt.close()
    
    # Criar relat√≥rio resumido
    print("\nüìÑ Gerando relat√≥rio resumido...")
    create_summary_report(all_results, "summary_report.png")
    
    # An√°lise de correla√ß√£o
    print("\nüîó An√°lise de correla√ß√£o entre ferramentas:")
    
    # Preparar dados para correla√ß√£o
    correlation_data = []
    for repo in all_repos:
        row = {
            'Repository': repo,
            'LLM_ZS': llm_zeroshot_data.get(repo, {}).get('total_smells', 0),
            'LLM_OS': llm_oneshot_data.get(repo, {}).get('total_smells', 0),
            'LLM_Cal': llm_calibrated_data.get(repo, {}).get('total_smells', 0),
            'PMD': pmd_data.get(repo, {}).get('total_smells', 0),
            'CheckStyle': checkstyle_data.get(repo, {}).get('total_smells', 0)
        }
        correlation_data.append(row)
    
    corr_df = pd.DataFrame(correlation_data)
    corr_matrix = corr_df[['LLM_ZS', 'LLM_OS', 'LLM_Cal', 'PMD', 'CheckStyle']].corr()
    
    # Heatmap de correla√ß√£o
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, linewidths=1, cbar_kws={"shrink": 0.8},
                fmt='.3f', ax=ax)
    ax.set_title("Matriz de Correla√ß√£o entre Ferramentas", fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, "correlation_matrix_tools.png"), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   Correla√ß√µes mais fortes:")
    # Encontrar correla√ß√µes mais fortes (excluindo diagonal)
    corr_values = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_values.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))
    
    corr_values.sort(key=lambda x: abs(x[2]), reverse=True)
    for tool1, tool2, corr in corr_values[:3]:
        print(f"   ‚Ä¢ {tool1} vs {tool2}: {corr:.3f}")
    
    # Salvar dados resumidos em CSV
    print("\nüíæ Salvando dados resumidos...")
    
    # Resumo geral
    summary_data = []
    for question, metrics in all_results.items():
        for metric, value in metrics.items():
            summary_data.append({
                'Quest√£o': question,
                'M√©trica': metric,
                'Valor': value
            })
    
    summary_df = pd.DataFrame(summary_data)
    summary_df.to_csv(os.path.join(OUTPUT_DIR, 'summary_metrics.csv'), index=False)
    
    # Dados detalhados por reposit√≥rio
    detailed_data = []
    for repo in all_repos:
        row = {
            'Repository': repo,
            'LLM_ZeroShot': llm_zeroshot_data.get(repo, {}).get('total_smells', 0),
            'LLM_OneShot': llm_oneshot_data.get(repo, {}).get('total_smells', 0),
            'LLM_Calibrated': llm_calibrated_data.get(repo, {}).get('total_smells', 0),
            'PMD': pmd_data.get(repo, {}).get('total_smells', 0),
            'CheckStyle': checkstyle_data.get(repo, {}).get('total_smells', 0)
        }
        detailed_data.append(row)
    
    detailed_df = pd.DataFrame(detailed_data)
    detailed_df.to_csv(os.path.join(OUTPUT_DIR, 'detailed_by_repository.csv'), index=False)
    
    print("\n" + "=" * 80)
    print("‚úÖ AN√ÅLISE CONCLU√çDA!")
    print("=" * 80)
    print(f"\nüìÅ Resultados salvos em: {os.path.abspath(OUTPUT_DIR)}")
    print("\nüìä Arquivos gerados:")
    print("   ‚Ä¢ Gr√°ficos de barras para cada quest√£o")
    print("   ‚Ä¢ Scatter plots comparativos")
    print("   ‚Ä¢ Heatmaps de diferen√ßas")
    print("   ‚Ä¢ Matriz de correla√ß√£o")
    print("   ‚Ä¢ Distribui√ß√£o de code smells")
    print("   ‚Ä¢ Relat√≥rio resumido visual")
    print("   ‚Ä¢ Arquivos CSV com dados detalhados")
    print("\nüéØ Total de visualiza√ß√µes criadas: 20+")

if __name__ == '__main__':
    main()